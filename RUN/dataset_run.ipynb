{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a19067",
   "metadata": {},
   "source": [
    "# Image Data set aquisition.\n",
    "This involves the gathering  of the dataset for the breast cancer classification project\n",
    "1. Create a directory called  unlabled_data_set in this directory in a directory at DATASETS/IMAGE-BASED-DATASET in the project directory.\n",
    "\n",
    "2. Download Data from Kaggle platform which has a description using the link \n",
    "    i. https://www.kaggle.com/datasets/orvile/mias-dataset\n",
    "    ii. unizip mostly comes with the name or something else  \n",
    "    iii. In the unlabled_data_set directory create a directory ./MIAS_DATA/mias_data_set\n",
    "    iv. Navigate to ./MIAS_DATA/mias_data_set and past all all the images in the unzipped file\n",
    "    v. Navigate to ./MIAS_DATA paste the mias_derived_info.csv in the unzipped file here.\n",
    "\n",
    "3. Download Data from kaggle platforms which has their discription using the following links \n",
    "    a. https://www.kaggle.com/datasets/phuchtlab/cbis-ddsm-classification\n",
    "    b. unzip and copy needed folder called \"cls_CBIS-DDSM\"\n",
    "    c. paste in the unlabled_data_set directory\n",
    "\n",
    "\n",
    "\n",
    "4. Download data from kaggle platform  using the link \n",
    "    a. https://www.kaggle.com/datasets/orvile/inbreast-dataset-bi-rads-classification\n",
    "    b. unzip if zipped and then copy the folder named birads1 and past in this directory(datasets)\n",
    "\n",
    "# Now follow each of the 6 cells to set the dataset up and ready for project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ddd4e9",
   "metadata": {},
   "source": [
    "# image Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c05e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the first set of images downloaded from MIAS\n",
    "mias_derived_info = pd.read_csv('../DATASETS/IMAGE-BASED-DATASET/unlabled_data_set/MIAS_DATA/mias_derived_info.csv')\n",
    "\n",
    "# Create a dictionary to store REFNUM to label mapping\n",
    "label_map = {}\n",
    "\n",
    "# Populate the label_map based on SEVERITY and CLASS_GROUP\n",
    "for refnum in mias_derived_info['REFNUM']:\n",
    "    row = mias_derived_info[mias_derived_info['REFNUM'] == refnum].iloc[0]\n",
    "    severity = row['SEVERITY']\n",
    "    group = row['CLASS_GROUP']\n",
    "\n",
    "    if severity == 'Normal' and group == 'Normal':\n",
    "        label_map[refnum] = 'N'\n",
    "    elif severity == 'Malignant' and group == 'Calcification':\n",
    "        label_map[refnum] = 'CALC'\n",
    "    elif severity == 'Benign' and group == 'Calcification':\n",
    "        label_map[refnum] = 'BC'\n",
    "    elif severity == 'Benign' and group == 'Masses':\n",
    "        label_map[refnum] = 'BM'\n",
    "    elif severity == 'Malignant' and group == 'Masses':\n",
    "        label_map[refnum] = 'M'\n",
    "\n",
    "# Define source and destination folders\n",
    "source_folder = '../DATASETS/IMAGE-BASED-DATASET/unlabled_data_set/MIAS_DATA/mias_data_set'\n",
    "destination_folder = '../DATASETS/IMAGE-BASED-DATASET/labled_data_set'\n",
    "\n",
    "# Create destination folder if it doesn't exist\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Rename and copy .png files based on the label mapping\n",
    "for refnum, label in label_map.items():\n",
    "    filename = f\"{refnum.lower()}.png\"\n",
    "    source_path = os.path.join(source_folder, filename)\n",
    "\n",
    "    if os.path.exists(source_path):\n",
    "        new_filename = f\"{refnum}_{label}.png\"\n",
    "        destination_path = os.path.join(destination_folder, new_filename)\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied: {filename} -> {new_filename}\")\n",
    "    else:\n",
    "        print(f\"File not found: {source_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the next set of images download ref:3. in cell 1\n",
    "csv_path = '../DATASETS/IMAGE-BASED-DATASET/unlabled_data_set/cls_CBIS-DDSM/calc_classifications/data_t1.csv'\n",
    "source_folder = '../DATASETS/IMAGE-BASED-DATASET/unlabled_data_set/cls_CBIS-DDSM/calc_classifications/origin_images'\n",
    "destination_folder = '../DATASETS/IMAGE-BASED-DATASET/labled_data_set'\n",
    "\n",
    "# Create destination folder if it doesn't exist\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Normalize column names just in case\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Go through each row in the CSV\n",
    "for _, row in df.iterrows():\n",
    "    filename = row['filename'].strip()\n",
    "    label = row['label'].strip().upper()\n",
    "\n",
    "    # Map label to tag\n",
    "    if label == 'MALIGNANT':\n",
    "        tag = 'CALC'\n",
    "    elif label in ['BENIGN', 'BENIGN_WITHOUT_CALLBACK']:\n",
    "        tag = 'BC'\n",
    "    else:\n",
    "        print(f\"Unknown label '{label}' for file '{filename}' — skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Build paths\n",
    "    source_path = os.path.join(source_folder, filename)\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    new_filename = f\"{base}_{tag}{ext}\"\n",
    "    destination_path = os.path.join(destination_folder, new_filename)\n",
    "\n",
    "    # Copy file with new name\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied: {filename} -> {new_filename}\")\n",
    "    else:\n",
    "        print(f\"File not found: {source_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the last set of images downloaded \n",
    "# Path to CSV and image folders\n",
    "csv_path = '../DATASETS/IMAGE-BASED-DATASET/unlabled_data_set/cls_CBIS-DDSM/mass_classifications/data_t1.csv'\n",
    "source_folder = '../DATASETS/IMAGE-BASED-DATASET/unlabled_data_set/cls_CBIS-DDSM/mass_classifications/origin_images'\n",
    "destination_folder = '../DATASETS/IMAGE-BASED-DATASET/labled_data_set'\n",
    "\n",
    "# Create destination folder if it doesn't exist\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Normalize column names just in case\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Go through each row in the CSV\n",
    "for _, row in df.iterrows():\n",
    "    filename = row['filename'].strip()\n",
    "    label = row['label'].strip().upper()\n",
    "\n",
    "    # Map label to tag\n",
    "    if label == 'MALIGNANT':\n",
    "        tag = 'M'\n",
    "    elif label in ['BENIGN', 'BENIGN_WITHOUT_CALLBACK']:\n",
    "        tag = 'BM'\n",
    "    else:\n",
    "        print(f\"Unknown label '{label}' for file '{filename}' — skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Build paths\n",
    "    source_path = os.path.join(source_folder, filename)\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    new_filename = f\"{base}_{tag}{ext}\"\n",
    "    destination_path = os.path.join(destination_folder, new_filename)\n",
    "\n",
    "    # Copy file with new name\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied: {filename} -> {new_filename}\")\n",
    "    else:\n",
    "        print(f\"File not found: {source_path}\")\n",
    "# Source and destination folders\n",
    "birads1_folder = '../DATASETS/IMAGE-BASED-DATASET/unlabled_data_set/birads1'\n",
    "destination_folder = '../DATASETS/IMAGE-BASED-DATASET/labled_data_set'\n",
    "\n",
    "# Create destination folder if it doesn't exist\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Loop through all files in birads1_folder\n",
    "for filename in os.listdir(birads1_folder):\n",
    "    # Only process image files\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        base, ext = os.path.splitext(filename)\n",
    "        new_filename = f\"{base}_N{ext}\"\n",
    "        source_path = os.path.join(birads1_folder, filename)\n",
    "        destination_path = os.path.join(destination_folder, new_filename)\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied: {filename} -> {new_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e527684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the labled_data_set folder\n",
    "result_folder = '../DATASETS/IMAGE-BASED-DATASET/labled_data_set'\n",
    "\n",
    "# Count the number of image files (e.g., .png, .jpg, .jpeg)\n",
    "image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "image_files = [f for f in os.listdir(result_folder) if f.lower().endswith(image_extensions)]\n",
    "\n",
    "print(f\"Number of image files in labled_data_set: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96aff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = '../DATASETS/IMAGE-BASED-DATASET/labled_data_set'\n",
    "image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(result_folder) if f.lower().endswith(image_extensions)]\n",
    "\n",
    "# Extract category from filename (assumes format: REFNUM_CATEGORY.png)\n",
    "categories = [f.split('_')[-1].split('.')[0] for f in image_files]\n",
    "\n",
    "# Count each category\n",
    "category_counts = Counter(categories)\n",
    "\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da92fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '../DATASETS/IMAGE-BASED-DATASET/labled_data_set'\n",
    "dst_folder = '../DATASETS/IMAGE-BASED-DATASET/data/mias'\n",
    "invalid_folder = '../DATASETS/IMAGE-BASED-DATASET/invalid_data_set'\n",
    "output_size = (299, 299)\n",
    "\n",
    "# Set desired sample sizes per category\n",
    "normal_size = 100\n",
    "calc_size = 100\n",
    "bc_size = 100\n",
    "m_size = 100\n",
    "bm_size = 100\n",
    "\n",
    "category_limits = {\n",
    "    'N': normal_size,\n",
    "    'CALC': calc_size,\n",
    "    'BC': bc_size,\n",
    "    'M': m_size,\n",
    "    'BM': bm_size\n",
    "}\n",
    "\n",
    "# Delete destination folder if it exists\n",
    "if os.path.exists(dst_folder):\n",
    "    shutil.rmtree(dst_folder)\n",
    "    print(f\"Existing '{dst_folder}' has been deleted.\")\n",
    "\n",
    "if os.path.exists(invalid_folder):\n",
    "    shutil.rmtree(invalid_folder)\n",
    "    print(f\"Existing '{invalid_folder}' has been deleted.\")\n",
    "\n",
    "# Create destination and invalid folders\n",
    "os.makedirs(dst_folder, exist_ok=True)\n",
    "os.makedirs(invalid_folder, exist_ok=True)\n",
    "\n",
    "# Group files by category\n",
    "image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "category_files = {cat: [] for cat in category_limits}\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(image_extensions):\n",
    "        category = filename.split('_')[-1].split('.')[0]\n",
    "        if category in category_files:\n",
    "            category_files[category].append(filename)\n",
    "\n",
    "# Randomly select files per category\n",
    "selected_files = []\n",
    "for cat, files in category_files.items():\n",
    "    sample_size = min(len(files), category_limits[cat])\n",
    "    selected = random.sample(files, sample_size)\n",
    "    selected_files.extend(selected)\n",
    "\n",
    "success_count = 0\n",
    "invalid_count = 0\n",
    "\n",
    "for filename in selected_files:\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    dst_path = os.path.join(dst_folder, filename)\n",
    "    invalid_path = os.path.join(invalid_folder, filename)\n",
    "    try:\n",
    "        # Read image in grayscale\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(\"Image could not be read (possibly corrupted or unsupported format)\")\n",
    "        # Resize image\n",
    "        img = cv2.resize(img, output_size, interpolation=cv2.INTER_AREA)\n",
    "        # Save processed image\n",
    "        cv2.imwrite(dst_path, img)\n",
    "        success_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        shutil.move(file_path, invalid_path)\n",
    "        invalid_count += 1\n",
    "\n",
    "print(f\"Selected and processed images have been moved to '{dst_folder}'.\")\n",
    "print(f\"Any invalid images have been moved to '{invalid_folder}'.\")\n",
    "print(f\"Successfully processed images: {success_count}\")\n",
    "print(f\"Invalid images: {invalid_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c46cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validated image statistics\n",
    "result_folder = '../DATASETS/IMAGE-BASED-DATASET/data/mias'\n",
    "image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(result_folder) if f.lower().endswith(image_extensions)]\n",
    "\n",
    "# Extract category from filename (assumes format: REFNUM_CATEGORY.png)\n",
    "categories = [f.split('_')[-1].split('.')[0] for f in image_files]\n",
    "\n",
    "# Count each category\n",
    "category_counts = Counter(categories)\n",
    "\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f774b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid image statistics\n",
    "result_folder = '../DATASETS/IMAGE-BASED-DATASET/invalid_data_set'\n",
    "image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(result_folder) if f.lower().endswith(image_extensions)]\n",
    "\n",
    "# Extract category from filename (assumes format: REFNUM_CATEGORY.png)\n",
    "categories = [f.split('_')[-1].split('.')[0] for f in image_files]\n",
    "\n",
    "# Count each category\n",
    "category_counts = Counter(categories)\n",
    "\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_to_delete = [\n",
    "    # '../DATASETS/IMAGE-BASED-DATASET/unlabled_data_set',\n",
    "    '../DATASETS/IMAGE-BASED-DATASET/labled_data_set',\n",
    "    '../DATASETS/IMAGE-BASED-DATASET/invalid_data_set'\n",
    "]\n",
    "\n",
    "for folder in folders_to_delete:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"'{folder}' has been deleted.\")\n",
    "    else:\n",
    "        print(f\"'{folder}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1c95c",
   "metadata": {},
   "source": [
    "# Feature extraction from image Dataset using Paper CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7572ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Feb 28 16:50:44 2021\n",
    "\n",
    "@author: Oyelade\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Constants and values describing rates and variables\n",
    "\"\"\"\n",
    "'''\n",
    "Settings from the paper\n",
    "--------------------------------------------------------------------------------------------\n",
    " Notation       Definition                                                     Range of Value\n",
    "--------------------------------------------------------------------------------------------\n",
    "    π     Recruitment rate of susceptible human individuals                          Variable\n",
    "    ŋ    Decay rate of Ebola virus in the environment                               (0, )\n",
    "    α    Rate of hospitalization of infected individuals                               (0, 1)\n",
    "        Disease-induced death rate of human individuals                               [0.4, 0.9]\n",
    "    β1    Contact rate of infectious human individuals                               Variable\n",
    "    β2    Contact rate of pathogen individuals/environment                           Variable\n",
    "    β3    Contact rate of deceased human individuals                                   Variable\n",
    "    β4    Contact rate of recovered human individuals                                   Variable\n",
    "        Recovery rate of human individuals                                           (0, 1)\n",
    "        Natural death rate of human individuals                                       (0, 1)\n",
    "        Rate of  burial of deceased human individuals                               (0, 1)\n",
    "        Rate of vaccination of individuals                                           (0, 1)\n",
    "        Rate of response to hospital treatment                                       (0, 1)\n",
    "        Rate response to vaccination                                               (0, 1)\n",
    "'''\n",
    "π=0.1 #Recruitment rate of susceptible human individuals\n",
    "ŋ=np.random.rand() #Decay rate of Ebola virus in the environment\n",
    "α=np.random.rand() #Rate of hospitalization of infected individuals\n",
    "dis=random.uniform(0.4, 0.9)#Disease-induced death rate of human individuals\n",
    "β_1=0.1#Contact rate of infectious human individuals\n",
    "β_2=0.1#Contact rate of pathogen individuals/environment\n",
    "β_3=0.1#Contact rate of deceased human individuals\n",
    "β_4=0.1#Contact rate of recovered human individuals\n",
    "rr=np.random.rand() #Recovery rate of human individuals\n",
    "dr=np.random.rand() #Natural death rate of human individuals\n",
    "br=np.random.rand() #Rate of  burial of deceased human individuals\n",
    "vr=np.random.rand() #Rate of vaccination of individuals\n",
    "hr=np.random.rand() #Rate of response to hospital treatment\n",
    "vrr=np.random.rand() #Rate response to vaccination\n",
    "qrr=np.random.rand()\t#Rate of quarantine of infected individuals\n",
    "\n",
    "modelrates = {\n",
    "    \"recruitment_rate\": π,\n",
    "    \"decay_rate\": ŋ,\n",
    "    \"hospitalization_rate\": α,\n",
    "    \"disease_induced_death_rate\": dis,\n",
    "    \"contact_rate_infectious\": β_1,\n",
    "    \"contact_rate_pathogen\": β_2,\n",
    "    \"contact_rate_deceased\": β_3,\n",
    "    \"contact_rate_recovered\": β_4,\n",
    "    \"recovery_rate\": rr,\n",
    "    \"natural_death_rate\": dr,\n",
    "    \"burial_rate\": br,\n",
    "    \"vacination_rate\": vr,\n",
    "    \"hospital_treatment_rate\": hr,\n",
    "    \"vaccination_response_rate\": vrr,\n",
    "    \"quarantine_rate\": qrr\n",
    "}\n",
    "modelrates = {\n",
    "    \"recruitment_rate\": π,\n",
    "    \"decay_rate\": ŋ,\n",
    "    \"hospitalization_rate\": α,\n",
    "    \"disease_induced_death_rate\": dis,\n",
    "    \"contact_rate_infectious\": β_1,\n",
    "    \"contact_rate_pathogen\": β_2,\n",
    "    \"contact_rate_deceased\": β_3,\n",
    "    \"contact_rate_recovered\": β_4,\n",
    "    \"recovery_rate\": rr,\n",
    "    \"natural_death_rate\": dr,\n",
    "    \"burial_rate\": br,\n",
    "    \"vacination_rate\": vr,\n",
    "    \"hospital_treatment_rate\": hr,\n",
    "    \"vaccination_response_rate\": vrr,\n",
    "    \"quarantine_rate\": qrr\n",
    "}\n",
    "\n",
    "'''\n",
    "Paths to datasets files\n",
    "'''\n",
    "input_base_dir='../Dataset/' #\n",
    "\n",
    "'''\n",
    "'mias numpy files: 299X299'\n",
    "all_mias_labels9 = os.path.join( \"..\", \"..\", \"Dataset\", 'miasNumpy', \"train\", \"all_mias_labels9.npy\")\n",
    "all_mias_slices9 = os.path.join( \"..\", \"..\", \"Dataset\", 'miasNumpy', \"train\", \"all_mias_slices9.npy\")\n",
    "mias_test_labels_enc= os.path.join( \"..\", \"..\", \"Dataset\", 'miasNumpy',\"test\", \"test12_labels.npy\")\n",
    "mias_test_images = os.path.join( \"..\", \"..\", \"Dataset\", 'miasNumpy', \"test\", \"test12_data.npy\")\n",
    "mias_val_labels_enc= os.path.join( \"..\", \"..\", \"Dataset\", 'miasNumpy',\"val\", \"all_mias_labels.npy\")\n",
    "mias_val_images = os.path.join( \"..\", \"..\", \"Dataset\",  'miasNumpy',\"val\", \"all_mias_slices.npy\")\n",
    "\n",
    "\n",
    "all_mias_labels9 = input_base_dir+'miasNumpy/train/all_mias_labels9.npy'\n",
    "all_mias_slices9 = input_base_dir+'miasNumpy/train/all_mias_slices9.npy'\n",
    "mias_test_labels_enc= input_base_dir+'miasNumpy/test/test12_labels.npy'\n",
    "mias_test_images = input_base_dir+'miasNumpy/test/test12_data.npy'\n",
    "mias_val_labels_enc= input_base_dir+'miasNumpy/val/all_mias_labels.npy'\n",
    "mias_val_images = input_base_dir+'miasNumpy/val/all_mias_slices.npy'\n",
    "'''\n",
    "\n",
    "'ddsm tfrecords files: 299x299 images and labels in tfrecords format'\n",
    "train_path_10 = os.path.join( \"..\", \"..\", \"Dataset\", \"ddsmTFrecords\", \"training10_0\", \"training10_0.tfrecords\")\n",
    "train_path_11 = os.path.join( \"..\", \"..\", \"Dataset\", \"ddsmTFrecords\", \"training10_1\",\"training10_1.tfrecords\")\n",
    "train_path_12 = os.path.join( \"..\", \"..\", \"Dataset\", \"ddsmTFrecords\", \"training10_2\", \"training10_2.tfrecords\")\n",
    "train_path_13 = os.path.join( \"..\", \"..\", \"Dataset\",  \"ddsmTFrecords\", \"training10_3\", \"training10_3.tfrecords\")\n",
    "train_path_14 = os.path.join( \"..\", \"..\", \"Dataset\",  \"ddsmTFrecords\", \"training10_4\", \"training10_4.tfrecords\")\n",
    "\n",
    "input_base_dir='./data/' #'/content/data/'\n",
    "'mias image files: 299x299'\n",
    "mias_input_dataset=input_base_dir+'mias/'\n",
    "\n",
    "\n",
    "'ddsm image files: 299x299'\n",
    "ddsm_input_dataset=input_base_dir+'ddsm/'\n",
    "\n",
    "'histopathology image files'\n",
    "histo_input_dataset=input_base_dir+'histo/'\n",
    "\n",
    "'''\n",
    "File and directory paths naming\n",
    "'''\n",
    "base_dir='./outputs/'  #'./outputs/' #\n",
    "histo_checkpoint_path=base_dir+'checkpoints/histo/'\n",
    "mammo_checkpoint_path=base_dir+'checkpoints/mammo/'\n",
    "models_path=base_dir+'models/'\n",
    "histo_model_filename='trainedmodelhisto'\n",
    "mammo_model_filename='trainedmodelmammo'\n",
    "save_results_dir=base_dir+'results/' \n",
    "save_histo_results_dir=save_results_dir+'training/histo/'\n",
    "save_mammo_results_dir=save_results_dir+'training/mammo/'\n",
    "metrics_dir=save_results_dir+'metrics/'\n",
    "fusion_info_dir=save_results_dir+'fusiondata/'\n",
    "optimize_fusion_info_dir=save_results_dir+'optimizedfusiondata/'\n",
    "\n",
    "'''\n",
    "General parameter settings\n",
    "'''\n",
    "show=1\n",
    "batch_size=64\n",
    "log_mode=1 \n",
    "number_of_runs=1\n",
    "cnn_epoch=40\n",
    "train_split=0.75\n",
    "test_split=0.15\n",
    "eval_split=0.10\n",
    "number_of_cnn_solutions=1\n",
    "train_using_histo='histology'\n",
    "train_using_mammo_ddsm='ddsm'\n",
    "train_using_mammo_mias='mias'\n",
    "isCombineMammoDatasets=False\n",
    "\n",
    "'''\n",
    "Image sizes\n",
    "'''\n",
    "histo_img_size={\"width\": 224, \"height\":224}\n",
    "mammo_img_size={\"width\": 299, \"height\":299}\n",
    "\n",
    "'''\n",
    "Image channels\n",
    "'''\n",
    "histo_num_channels=3\n",
    "mammo_num_channels=1\n",
    "\n",
    "'''\n",
    "Image labels\n",
    "'''\n",
    "histo_classes={\"N\":0, #normal (BACH dataset) \n",
    "         \"B\":1, #benign (BACH dataset) \n",
    "         \"IS\":2, #in situ carcinoma (BACH dataset)\n",
    "         \"IV\":3, #invasive carcinoma, (BACH dataset)\n",
    "         \"A\":4, #adenosis as benign (BreakHis dataset)\n",
    "         \"F\":5, #fibroadenoma as benign (BreakHis dataset)\n",
    "         \"PT\":6, #phyllodes tumor as benign (BreakHis dataset)\n",
    "         \"TA\":7, #tubular adenona as benign (BreakHis dataset)\n",
    "         \"DC\":8, #carcinoma as malignant (BreakHis dataset)\n",
    "         \"LC\":9, #lobular carcinoma as malignant (BreakHis dataset)\n",
    "         \"MC\":10, #mucinous carcinoma as malignant (BreakHis dataset)\n",
    "         \"PC\":11 #papillary carcinoma as malignant (BreakHis dataset)\n",
    "        }\n",
    "histo_named_classes=[\"N\",\"B\",\"IS\", \"IV\",\"A\",\"F\",\"PT\", \"TA\", \"DC\", \"LC\", \"MC\",\"PC\"]\n",
    "\n",
    "#Mias image class info\n",
    "mammo_mias_named_classes=['N', 'BC', 'BM', 'CALC', 'M']\n",
    "mammo_mias_classes={0:'N', 1:'BC', 2:'BM', 3:'CALC', 4:'M'}\n",
    "\n",
    "#DDSM image class info\n",
    "mammo_ddsm_named_classes=['N', 'BC', 'BM', 'CALC', 'M']\n",
    "mammo_ddsm_classes={0:'N', 1:'BC', 2:'BM', 3:'CALC', 4:'M'}\n",
    "\n",
    "\n",
    "#seven(7) classes in MIAS numpy version\n",
    "mias_numpy_classes=['CALC', #Calcification \n",
    "                  'CIRC', #Well-defined /circumscribed masses\n",
    "                  'SPIC',  #Spiculated masses,\n",
    "                  'M', #Other, ill-defined masses  MISC\n",
    "                  'ARCH', #Architectural distortion\n",
    "                  'ASY', #Asymmetry\n",
    "                  'N',  #Normal\n",
    "                  ]\n",
    "\n",
    "\n",
    "'''\n",
    "Definition of hyper-parameters\n",
    "'''\n",
    "learning_rates={0:1e-00, 1:1e-01, 2:1e-02, 3:1e-03, 4:1e-04, 5:1e-05, 6:1e-06, 7:1e-07, 8:1e-08,\n",
    "                9:5e-00, 10:5e-01, 11:5e-02, 12:5e-03, 13:5e-04, 14:5e-05, 15:5e-06, 16:5e-07, 17:5e-08}\n",
    "\n",
    "optimizers={0:\"SGD\", 1:\"Adam\", 2:\"RMSprop\", 3:\"Adagrad\", 4:\"Nestrov\", 5:\"Adadelta\", 6:\"Adamax\", 7:\"Momentum\"}\n",
    "\n",
    "activations={0:\"relu\", 1:\"leakyrelu\", 2:\"waveletdecompfunc\"}\n",
    "\n",
    "pooling={0:\"Max\", 1:\"Avg\"}\n",
    "\n",
    "regularizers={0:\"L1\", 1:\"L2\", 2:\"L1L2\"}\n",
    "\n",
    "fcactivations={0:\"softmax\"}\n",
    "\n",
    "lossfunc={0: 'categorical_crossentropy', 1: 'sparse_categorical_crossentropy', 2: 'binary_crossentropy'}\n",
    "\n",
    "\n",
    "'''\n",
    "Binary optimization algorithms to use for experimentation\n",
    "'''\n",
    "binaryalgorithms=[ 'HBEOSA-DMO', 'HBEOSA-DMO-NT', 'HBEOSA-PSO', 'HBEOSA-PSO-NT', 'BEOSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K  #from keras import backend as K\n",
    "from numpy import array\n",
    "# from cnn.root.rootcnn import RootCNN\n",
    "#from keras.utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "from time import time\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "class InputProcessor(object):\n",
    "    REGULARIZER_RATES=0.0002\n",
    "\n",
    "    # this is the constructor function \n",
    "    def __init__(self, data_params=None):\n",
    "        self.num_classes=data_params[\"num_classes\"]\n",
    "        self.classes=data_params[\"class_names\"]\n",
    "        self.input_dataset=data_params['input_dataset'] #has localtion to the files \n",
    "        self.testing_dataset=data_params['testing_dataset']\n",
    "        self.img_width=data_params[\"img_size\"][\"width\"] \n",
    "        self.img_height=data_params[\"img_size\"][\"height\"]\n",
    "        self.num_channels=data_params[\"num_channels\"]\n",
    "        self.train_using=data_params[\"train_using\"]\n",
    "        self.train_split=data_params[\"train_split\"]\n",
    "        self.test_split=data_params[\"test_split\"]\n",
    "        self.eval_split=data_params[\"eval_split\"]\n",
    "        self.K=data_params[\"K\"]\n",
    "        self.x_train, self.y_train=[], []\n",
    "        self.x_eval, self.y_eval=[], [],\n",
    "        self.x_test, self.y_test=[], [],\n",
    "        self.img_ids_train, self.img_ids_eval, self.img_ids_test=[], [], []\n",
    "\n",
    "    #get train input\n",
    "    #this function is called  by the get train_input function \n",
    "    def init_imgs(self, nFiles):\n",
    "        dim=(self.img_width, self.img_height, self.num_channels) #gives us the diminitions of the various various images in the data set(like width,height,channel if 1 or 3)\n",
    "        img_data_array = np.empty((nFiles, self.img_width, self.img_height, self.num_channels)) #this is the array that will hold the images(array of arrays that represent the various images)\n",
    "        self.x_train, self.y_train=np.empty((0, self.img_width, self.img_height, self.num_channels)), np.empty((0, )) # this sets  array that will hold the training images(array of arrays that represent the various images)\n",
    "        self.x_eval, self.y_eval=np.empty((0, self.img_width, self.img_height, self.num_channels)), np.empty((0, )) # this sets array that will hold the evaluation images(array of arrays that represent the various images)\n",
    "        self.x_test, self.y_test=np.empty((0, self.img_width, self.img_height, self.num_channels)), np.empty((0, )) # this sets  array that will hold the testing images(array of arrays that represent the various images)\n",
    "        return img_data_array, dim\n",
    "    \n",
    "\n",
    "    def get_train_input(self):\n",
    "        nFiles=len(os.listdir(self.input_dataset)) #show the number of files in the database\n",
    "        img_ids=[]\n",
    "        num_imgs_per_label = {}\n",
    "\n",
    "        img_data_array, dim=self.init_imgs(nFiles)   # this is what will execute  we use this function to \n",
    "        # print(img_data_array, dim) \n",
    "        class_name = np.empty((nFiles, ))            \n",
    "        num_imgs_per_label={'N': 0, 'BC': 0, 'BM': 0, 'CALC': 0, 'M': 0}\n",
    "        n =0\n",
    "        prev_label=''\n",
    "        keys=list(self.classes.keys()) #this is the list of keys in the dictionary that contains the class names \n",
    "        values=list(self.classes.values())  #this is the list of values in the dictionary that contains the class names\n",
    "        # print(keys,values)\n",
    "        \n",
    "        for file in os.listdir(self.input_dataset):\n",
    "            if file.endswith(('jpg', 'png')):\n",
    "                image_path= os.path.join(self.input_dataset, file)\n",
    "                image= cv2.imread( image_path, cv2.COLOR_BGR2GRAY) #image= np.array(Image.open(image_path)) COLOR_BGR2GRAY\n",
    "                image=cv2.resize(image, (self.img_width, self.img_height),interpolation = cv2.INTER_AREA) #resize the image to the specified width and height\n",
    "\n",
    "                zrows, zcols= image.shape[0], image.shape[1]\n",
    "                image=np.array(image) # collect the image to an array \n",
    "                image = image.astype('float32') # convert the image to a float32\n",
    "                image=image.reshape(dim) # reshape the image to the specified dimention\n",
    "                image /= 255 # reduce the normalize the image to range form 0 to 1\n",
    "\n",
    "                label=(file.split('_')[-1]).split('.')[0]   \n",
    "                tmpf=label #we try to extract a label form the file name. by splitting the first part of ht file name by _ select the first part and spit by . and pick the first part.\n",
    "                \n",
    "                value_at_index = values.index(tmpf) #keys[values.index(label)]\n",
    "                label = value_at_index                    \n",
    "                img_data_array[n, :, :, :] = image # add this to the image data \n",
    "                class_name[n] = label # store its corresponding label for it \n",
    "                num_imgs_per_label[tmpf]=num_imgs_per_label[tmpf] + 1  # we try to get statistics for the various images labels \n",
    "                n=n+1\n",
    "        \n",
    "        class_name=array(class_name)\n",
    "        class_name = to_categorical(class_name, self.num_classes)\n",
    "        \n",
    "        # we set the various arrays to contain  our spit data and set the various labels to contain the labels of the images while me make this to be a categorical value\n",
    "        self.y_train=array(self.y_train)\n",
    "        self.y_train = to_categorical(self.y_train, self.num_classes)\n",
    "        \n",
    "        self.y_eval=array(self.y_eval) \n",
    "        self.y_eval = to_categorical(self.y_eval, self.num_classes)\n",
    "        \n",
    "        self.y_test=array(self.y_test)\n",
    "        self.y_test = to_categorical(self.y_test, self.num_classes)\n",
    "        \n",
    "       \n",
    "        clabel_count=0\n",
    "        \n",
    "        # based on each label we add the various training, test, and eval data to the total train, test, and eval data set \n",
    "        for clabel, count in num_imgs_per_label.items():\n",
    "            train_split = int(self.train_split * count) \n",
    "            test_split = int(self.test_split * count) \n",
    "            eval_split = int(self.eval_split * count) \n",
    "            \n",
    "            print(clabel, \":\", count, \":\", train_split, \":\", eval_split, \":\", test_split)#show the various categories and the number of images in it and the number of images in the train test and eval set\n",
    "\n",
    "            train_stop=(clabel_count+train_split)\n",
    "            self.x_train=np.concatenate((self.x_train,img_data_array[clabel_count:train_stop]))\n",
    "            self.y_train=np.concatenate((self.y_train,class_name[clabel_count:train_stop]))\n",
    "            \n",
    "            eval_start=train_stop+1\n",
    "            eval_end=(eval_start+eval_split)\n",
    "            self.x_eval=np.concatenate((self.x_eval, img_data_array[eval_start:eval_end])) \n",
    "            self.y_eval=np.concatenate((self.y_eval, class_name[eval_start:eval_end]))       \n",
    "            \n",
    "            test_start=eval_end+1\n",
    "            test_end=(test_start+test_split)\n",
    "            self.x_test=np.concatenate((self.x_test, img_data_array[test_start:test_end]))  \n",
    "            self.y_test=np.concatenate((self.y_test, class_name[test_start:test_end]))\n",
    "            \n",
    "            # print(clabel_count, \"-\", train_stop, \",\", eval_start, \"-\", eval_end, \",\", test_start, \"-\", test_end)\n",
    "            # clabel_count=clabel_count+count\n",
    "\n",
    "        print('finally this is what we have as our training, eval and test')\n",
    "        print('train_data',len(self.x_train))\n",
    "        print('eval_data',len(self.x_eval))\n",
    "        print('test_data',len(self.x_test))\n",
    "\n",
    "    \n",
    "    #this functions are used to get train , eval, test data\n",
    "    def get_training_data(self):\n",
    "        return self.x_train, self.y_train\n",
    "    \n",
    "    def get_eval_data(self):\n",
    "        return self.x_eval, self.y_eval\n",
    "    \n",
    "    def get_test_data(self):\n",
    "        return self.x_test, self.y_test\n",
    "    \n",
    "    #this is used to set or add on to the training, test or eval data\n",
    "    def set_training_data(self, x, y):\n",
    "         self.x_train, self.y_train=np.concatenate(self.x_train,x), np.concatenate(self.y_train,x)\n",
    "         return None\n",
    "    \n",
    "    def set_eval_data(self, x, y):\n",
    "        self.x_eval, self.y_eval=np.concatenate(self.x_eval,x), np.concatenate(self.y_eval,y)\n",
    "        return None\n",
    "    \n",
    "    def set_test_data(self, x, y):\n",
    "        self.x_test, self.y_test=np.concatenate(self.x_test,x), np.concatenate(self.y_test,y)\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e01205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.regularizers import l1, l2, L1L2\n",
    "# from tensorflow.keras.regularizers import l1, l2, L1L2\n",
    "#from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, Concatenate, Reshape, Activation\n",
    "#from tensorflow.python.keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, Concatenate, Reshape, Activation\n",
    "from keras.optimizers import SGD, Adam, Adadelta, RMSprop, Adagrad, Adamax\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from time import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class RootCNN(object):\n",
    "    REGULARIZER_RATES=0.0002\n",
    "       \n",
    "    def __init__(self, root_params=None):\n",
    "        self.num_classes = root_params[\"num_classes\"]\n",
    "        self.class_names = root_params[\"class_names\"]\n",
    "        self.img_width=root_params[\"img_size\"][\"width\"] \n",
    "        self.img_height=root_params[\"img_size\"][\"height\"]\n",
    "        self.activations=root_params[\"activations\"]\n",
    "        self.epoch=root_params[\"cnn_epoch\"]\n",
    "        self.batch_size=root_params[\"batch_size\"]\n",
    "        self.log=root_params[\"log_mode\"]\n",
    "        self.models_path=root_params[\"models_path\"]\n",
    "        self.model_filename=root_params[\"model_filename\"]\n",
    "        self.checkpoint_path=root_params[\"checkpoint_path\"]\n",
    "        self.checkpoint_epoch=root_params[\"checkpoint_epoch\"]\n",
    "        self.fromCheckpoint=root_params[\"fromCheckpoint\"]        \n",
    "        self.path_save_result=root_params[\"save_results_dir\"]\n",
    "        self.show=root_params[\"show\"]        \n",
    "        self.num_channels=root_params[\"num_channels\"]\n",
    "        self.input_source=root_params[\"input_source\"]\n",
    "        self.K=root_params[\"K\"]\n",
    "        self.session=None\n",
    "    \n",
    "    def cnn_input(self, model_type=0, is_zeropad=None):\n",
    "        channel='channels_first'\n",
    "        #K.set_image_data_format('channels_last')\n",
    "        if model_type==0:\n",
    "            input_shape=(None, self.num_channels, self.img_width, self.img_height) if self.K.image_data_format() ==channel  else (None, self.img_width, self.img_height, self.num_channels)\n",
    "            inputs =ZeroPadding2D((1,1), \n",
    "                                  input_shape=\n",
    "                                  (self.num_channels, self.img_width, self.img_height)\n",
    "                                  if self.K.image_data_format() == channel \n",
    "                                  else (self.img_width, self.img_height, self.num_channels)) if is_zeropad else input_shape\n",
    "        else:\n",
    "            input_shape=(self.num_channels, self.img_width, self.img_height) if self.K.image_data_format() == channel else (self.img_width, self.img_height, self.num_channels)\n",
    "            inputs = ZeroPadding2D(padding=(1, 1))(input_shape) if is_zeropad else input_shape\n",
    "        return inputs, input_shape\n",
    "        \n",
    "    def _2Dconvolution__(self, convo_number=None, cf=None, ck=None, activation=None, regularizer=None, is_first=False, input_pad=None,is_zeropad=False):\n",
    "        regularizer=self.get_regularizer()         \n",
    "        if is_first and not(is_zeropad):\n",
    "            convo2d=Conv2D(int(ck), (int(cf),int(cf)), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=activation), \n",
    "                           input_shape=input_pad,  \n",
    "                       name='conv_'+str(convo_number), kernel_regularizer=regularizer)         \n",
    "        return convo2d\n",
    "    \n",
    "    def _2Dpool__(self, pnumber=None, pfilter=None, ptype=None):\n",
    "        if ptype==\"Max\": #data_format=\"channels_first\",\n",
    "            pool = MaxPooling2D(pool_size=(int(pfilter), int(pfilter)), strides=(2,2), padding='same',  name='pool_'+str(pnumber))        \n",
    "        else:\n",
    "            pool = AveragePooling2D(pool_size=(int(pfilter), int(pfilter)), strides=(2,2), padding='same', name='pool_'+str(pnumber))\n",
    "        return pool\n",
    "    \n",
    "    def flaten(self):\n",
    "        return Flatten()\n",
    "    \n",
    "    def architecture_summary(self, model=None, input_shape=None):\n",
    "        model.build(input_shape)\n",
    "        return model.summary()\n",
    "        \n",
    "    def fully_dense(self, activation=None, dropout=None, model=None):\n",
    "        regularizer=self.get_regularizer('L1')         \n",
    "        model.add(Dropout(rate=float(dropout)))     \n",
    "        model.add(Dense(self.num_classes, name='loss_classifier_0', kernel_regularizer=regularizer))\n",
    "        model.add(Activation(activation, name='class_prob'))\n",
    "        return model                    \n",
    "    \n",
    "    def get_regularizer(self, regularizer=None):\n",
    "        print(f\"Regularizer type: {regularizer}, Rate: {self.REGULARIZER_RATES}\")  # Debugging line\n",
    "\n",
    "        if regularizer==\"L1\" :\n",
    "            regularizer=l1(self.REGULARIZER_RATES)\n",
    "        elif regularizer==\"L2\":\n",
    "            regularizer=l2(self.REGULARIZER_RATES)\n",
    "        else: \n",
    "            regularizer=L1L2(self.REGULARIZER_RATES)\n",
    "\n",
    "        return regularizer\n",
    "    \n",
    "    def get_activation_function(self, func=None):        \n",
    "        if func=='leakyrelu':\n",
    "            return tf.keras.layers.LeakyReLU(alpha=0.1)\n",
    "        elif func=='parametricrelu':\n",
    "            return tf.keras.layers.PReLU() #alpha=0.1\n",
    "        else:\n",
    "            return func\n",
    "        \n",
    "    def load_trained_model(self, x_train, y_train, x_eval, y_eval): \n",
    "        if self.fromCheckpoint:\n",
    "            checkpoint_dir = os.path.dirname(self.checkpoint_path)\n",
    "            latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "            self.model.load_weights('./outputs/checkpoints/mammo/trainedmodelmammo.h5')\n",
    "            #self.get_fc_features__(model=self.model, x_train=x_train, y_train=y_train)\n",
    "            \n",
    "        loss_train, accuracy_train, loss_eval, accuracy_eval,time_total_train=self.trainmodel(model=self.model, x_train=x_train, y_train=y_train, x_eval=x_eval, y_eval=y_eval)\n",
    "        return loss_train, accuracy_train, loss_eval, accuracy_eval, time_total_train\n",
    "    \n",
    "    def config(self):\n",
    "        if self.K.backend() == 'tensorflow':\n",
    "            config = tf.compat.v1.ConfigProto() \n",
    "            config.gpu_options.per_process_gpu_memory_fraction = 0.333\n",
    "            session = tf.compat.v1.Session(config=config) \n",
    "            #session = tf.compat.v1.Session(graph=tf.Graph())\n",
    "            self.session=session\n",
    "            set_session(session)\n",
    "            # Using the Winograd non-fused algorithms provides a small performance boost.\n",
    "            os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
    "            os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "            #To not use GPU, a good solution is to not allow the environment to see any GPUs by setting the environmental variable CUDA_VISIBLE_DEVICES.\n",
    "            os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "            os.environ[\"OMP_NUM_THREADS\"] = \"NUM_PARALLEL_EXEC_UNITS\"\n",
    "            os.environ[\"KMP_BLOCKTIME\"] = \"30\"\n",
    "            os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "            os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\n",
    "            \n",
    "    def compile_model(self, model=None, optimizer=None, learning_rate=None, lossfunc=None):\n",
    "        momentum=0.9 #0.0,  0.5,  0.9,  0.99\n",
    "        if optimizer == 'SGD':\n",
    "            optim = SGD(lr=learning_rate, decay=1e-6, momentum=momentum, nesterov=True)\n",
    "        elif optimizer == 'RMSprop':\n",
    "            optim = tf.keras.optimizers.RMSprop(learning_rate=learning_rate,rho=0.9,momentum=momentum,epsilon=1e-07, centered=False, name=\"RMSprop\")\n",
    "        elif optimizer == 'Adagrad':\n",
    "            optim = tf.keras.optimizers.Adagrad(learning_rate=learning_rate, initial_accumulator_value=0.1,epsilon=1e-07,name=\"Adagrad\")\n",
    "        elif optimizer == 'Adam': #adam\n",
    "            optim=Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-8) \n",
    "        elif optimizer == 'Adadelta': #Adadelta\n",
    "            optim=Adadelta(lr=learning_rate, rho=0.95, epsilon=1e-07, name=\"Adadelta\")\n",
    "        elif optimizer == 'Adamax': #Adamax\n",
    "            optim=Adamax(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07) #, name=\"Adamax\"\n",
    "        elif optimizer == 'Momentum': #Momentum\n",
    "            optim=SGD(lr=learning_rate, decay=1e-6, momentum=momentum, nesterov=False)\n",
    "        else: #optimizer == 'Nestrov': #Nestrov\n",
    "            optim= SGD(lr=learning_rate, decay=1e-6, momentum=0.0, nesterov=True)\n",
    "        \n",
    "        model.compile(optimizer=optim, loss=lossfunc, metrics=['accuracy']) #'categorical_crossentropy' \n",
    "\n",
    "        return model\n",
    "    \n",
    "    def trainmodel(self, model=None, x_train=None, y_train=None, x_eval=None, y_eval=None):\n",
    "        time_total_train = time()\n",
    "        checkpoint_path = self.checkpoint_path + 'cp-{epoch:04d}.weights.h5'\n",
    "        # checkpoint_path=self.checkpoint_path+'cp-{epoch:04d}.ckpt'#.format(self.epoch)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=0, save_weights_only=True,save_freq='epoch')\n",
    "        # model = ResumableModel(model, save_every_epochs=1, custom_objects=None, to_path=self.checkpoint_path)\n",
    "        print(x_train.shape, y_train.shape)\n",
    "        ml = model.fit(x_train, y_train, \n",
    "                       epochs=self.epoch, \n",
    "                       initial_epoch=self.checkpoint_epoch,\n",
    "                       validation_data=(x_eval, y_eval),\n",
    "                       #steps_per_epoch=int(x_train.shape[0]//self.batch_size),\n",
    "                       batch_size=self.batch_size,  \n",
    "                       #callbacks=[cp_callback],\n",
    "                       verbose=self.log)\n",
    "        print(ml)\n",
    "        print(\"test loss, test acc:\", ml.history)\n",
    "        print(\"Evaluate on test data\")\n",
    "        # results = model.evaluate(x_eval, y_eval, batch_size=self.batch_size)\n",
    "        # print(\"evaluation result\", results)\n",
    "        time_total_train = round(time() - time_total_train, 4)\n",
    "        \n",
    "        loss_train = None #ml.history[\"loss\"] #ml[\"loss\"] # \n",
    "        accuracy_train =  None # ml.history[\"accuracy\"] #  ml[\"acc\"] # \n",
    "        loss_eval =  None #ml.history[\"val_loss\"] #ml[\"val_loss\"] #\n",
    "        accuracy_eval =  None #ml.history[\"val_accuracy\"]   #ml[\"val_acc\"] #\n",
    "        self.save_model(model)\n",
    "        return loss_train, accuracy_train, loss_eval, accuracy_eval, time_total_train,\n",
    "    \n",
    "    def save_model(self, model=None):\n",
    "        # pathf=self.path_save_result+self.model_filename\n",
    "        pathf_h5=self.path_save_result+self.model_filename+'.h5'\n",
    "        # model.save(pathf)\n",
    "        model.save(pathf_h5)\n",
    "        # tf.keras.models.save_model()\n",
    "        \n",
    "    def predict(self, x=None, y=None):\n",
    "        if x==None and y==None:\n",
    "            x_test, y_test=self.input_source.get_test_data() \n",
    "        else:\n",
    "            x_test, y_test=x, y\n",
    "        time_predict, avg_pred, y_test, y_pred, x_test=self.predictmodel(model=self.model, x_test=x_test, y_test=y_test)\n",
    "        return time_predict, avg_pred, y_test, y_pred, x_test\n",
    "    \n",
    "    def predictmodel(self, model=None, x_test=None, y_test=None):\n",
    "        time_predict = time()\n",
    "        y_pred = model.predict(x_test)\n",
    "        avg_pred=tf.keras.losses.categorical_crossentropy(y_pred, y_test)\n",
    "        time_predict = round(time() - time_predict, 8)\n",
    "        return time_predict, avg_pred, y_test, y_pred, x_test\n",
    "    \n",
    "    def extract_vector_features(self, model=None, x_train=None, y_train=None, x_eval=None, y_eval=None, layer_name=None):\n",
    "        latest = \"./outputs/results/trainedmodelmammo.h5\"\n",
    "        model.load_weights(latest)\n",
    "\n",
    "        # Create a new model that outputs features from the specified layer\n",
    "        intermediate_model = tf.keras.models.Model(\n",
    "            inputs=model.inputs,\n",
    "            outputs=model.get_layer(name=layer_name).output\n",
    "        )\n",
    "\n",
    "        # Get output shape (use .output_shape instead of .output_shape on the layer)\n",
    "        layer_shape = intermediate_model.output_shape  # Returns (batch_size, height, width, channels)\n",
    "        # print(f\"Layer shape: {layer_shape}\")\n",
    "\n",
    "        # Extract features\n",
    "        train_features = intermediate_model.predict(x_train)\n",
    "        train_features = np.reshape(train_features, (x_train.shape[0], np.prod(layer_shape[1:])))  # Flatten (batch, H*W*C)\n",
    "        \n",
    "        test_features = intermediate_model.predict(x_eval)\n",
    "        test_features = np.reshape(test_features, (x_eval.shape[0], np.prod(layer_shape[1:])))\n",
    "\n",
    "        print(f\"Train features shape: {train_features.shape}\")\n",
    "        print(f\"Test features shape: {test_features.shape}\")\n",
    "\n",
    "        # Ensure the checkpoint directory exists\n",
    "        os.makedirs(self.checkpoint_path, exist_ok=True)  # <-- Fix: Create directory if missing\n",
    "\n",
    "        # Save extracted features\n",
    "        np.save(self.checkpoint_path + \"train_features.npy\", train_features)\n",
    "        np.save(self.checkpoint_path + \"train_labels.npy\", y_train)\n",
    "        np.save(self.checkpoint_path + \"validation_features.npy\", test_features)\n",
    "        np.save(self.checkpoint_path + \"validation_labels.npy\", y_eval)\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def optimize_vector_features(self,x_train=None, y_train=None, x_eval=None, y_eval=None):\n",
    "        #print(self.checkpoint_path)\n",
    "        train_features = np.load(self.checkpoint_path+\"train_features.npy\")\n",
    "        train_labels = np.load(self.checkpoint_path+\"train_labels.npy\")\n",
    "        validation_labels = np.load(self.checkpoint_path+\"validation_labels.npy\")\n",
    "        validation_features = np.load(self.checkpoint_path+\"validation_features.npy\")\n",
    "        whole_feat=np.concatenate((train_features,validation_features))\n",
    "        whole_label=np.concatenate((train_labels,validation_labels))        \n",
    "        lb, ub=whole_feat.shape[1]//8, whole_feat.shape[1]\n",
    "        return lb, ub, train_features, y_train, validation_features, y_eval# train_labels, validation_labels\n",
    "    \n",
    "    def get_extracted_features(self, model=None, x_train=None, y_train=None):\n",
    "        '''\n",
    "        checkpoint_dir = os.path.dirname(self.checkpoint_path)\n",
    "        latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "        model.load_weights(self.checkpoint_path+'cp-0025.ckpt')#latest)            \n",
    "        '''\n",
    "        #Create a new model \n",
    "        old_model=model\n",
    "        model =tf.keras.models.Model(inputs=model.inputs, #name=\"pool_5\"\n",
    "                                     outputs=model.get_layer(index=2).output,)             \n",
    "        train_features = np.zeros(shape=(x_train.shape[0], 5, 5, 1024)) #because this is the shape of the last layer: 'pool_23''\n",
    "        train_features = model.predict(x_train)            \n",
    "        print(x_train.shape[0])\n",
    "        print(len(y_train))\n",
    "        print(train_features.shape)\n",
    "        print(train_features.shape[0])            \n",
    "        train_features = np.reshape(train_features, (x_train.shape[0], 5 * 5 * 1024))            \n",
    "        np.save(self.checkpoint_path+\"train_features.npy\", train_features)\n",
    "        np.save(self.checkpoint_path+\"train_labels.npy\", y_train)\n",
    "        \n",
    "        pca = PCA(n_components=100, whiten=True)\n",
    "        X_pca = pca.fit_transform(train_features)\n",
    "        #print(X_pca)\n",
    "        print(\"Original number of features:\", train_features.shape)\n",
    "        print(\"Reduced number of features:\", X_pca.shape)\n",
    "        return old_model\n",
    "         \n",
    "    '''\n",
    "    def _get_average_error__(self, individual=None, X_data=None, y_data=None):\n",
    "        t1 = time()\n",
    "        weights = [rand(*w.shape) for w in self.model_rnn.get_weights()]\n",
    "        ws = []\n",
    "        cur_point = 0\n",
    "        for wei in weights:\n",
    "            ws.append(reshape(individual[cur_point:cur_point + len(wei.reshape(-1))], wei.shape))\n",
    "            cur_point += len(wei.reshape(-1))\n",
    "\n",
    "        self.model_rnn.set_weights(ws)\n",
    "        y_pred = self.model_rnn.predict(X_data)\n",
    "        # print(\"GAE time: {}\".format(time() - t1))\n",
    "\n",
    "        # return [mean_squared_error(y_pred, y_data), mean_absolute_error(y_pred, y_data)]\n",
    "        return tf.keras.losses.categorical_crossentropy(y_pred, y_data)\n",
    "\n",
    "    def _objective_function__(self, solution=None):\n",
    "        weights = [rand(*w.shape) for w in self.model_rnn.get_weights()]\n",
    "        ws = []\n",
    "        cur_point = 0\n",
    "        for wei in weights:\n",
    "            ws.append(reshape(solution[cur_point:cur_point + len(wei.reshape(-1))], wei.shape))\n",
    "            cur_point += len(wei.reshape(-1))\n",
    "\n",
    "        self.model_rnn.set_weights(ws)\n",
    "        y_pred = self.model_rnn.predict(self.X_train)\n",
    "        return tf.keras.losses.categorical_crossentropy(y_pred, self.y_train)\n",
    "    '''\n",
    "    \n",
    "    def predict_single_img(image):\n",
    "        image = image.resize((200, 200))\n",
    "        '''\n",
    "        image = img_to_array(image)\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "        image = image / 255\n",
    "        pred = np.argmax(model.predict(image))\n",
    "        return labels[pred]\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc37fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, Concatenate, Reshape, Activation\n",
    "#from tensorflow.python.keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, Concatenate, Reshape, Activation\n",
    "from keras.models import Sequential\n",
    "from cnn.root.rootcnn import RootCNN\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.engine import keras_tensor\n",
    "\n",
    "class MammoCNN(RootCNN):\n",
    "    REGULARIZER_RATES=0.0002\n",
    "    \n",
    "    def __init__(self, mamocnn_paras=None):\n",
    "        RootCNN.__init__(self, mamocnn_paras)\n",
    "        self.learning_rates=mamocnn_paras[\"learning_rates\"]\n",
    "        self.optimizers=mamocnn_paras[\"optimizers\"]\n",
    "        self.activations=mamocnn_paras[\"activations\"]\n",
    "        self.pooling=mamocnn_paras[\"pooling\"]\n",
    "        self.regularizers=mamocnn_paras[\"regularizers\"]\n",
    "        self.fcactivations=mamocnn_paras[\"fcactivations\"]\n",
    "        self.lossfunc=mamocnn_paras[\"lossfunc\"]\n",
    "        self.cnn_epoch=mamocnn_paras[\"cnn_epoch\"]\n",
    "        self.config()\n",
    "\n",
    "    def build_architecture(self):  \n",
    "        self.model = Sequential()\n",
    "        inputs, input_shape=self.cnn_input(model_type=0, is_zeropad=True)\n",
    "        self.model.add(inputs)\n",
    "        \n",
    "        #block 1\n",
    "        self.model.add(Conv2D(32, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_1_1', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(Conv2D(32, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_1_2', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(self._2Dpool__(pnumber=1, pfilter=2, ptype=self.pooling))\n",
    "        \n",
    "        #block 2\n",
    "        self.model.add(Conv2D(64, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_2_1', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(Conv2D(64, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_2_2', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(self._2Dpool__(pnumber=2, pfilter=2, ptype=self.pooling))\n",
    "        \n",
    "        #block 3\n",
    "        self.model.add(Conv2D(128, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_3_1', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(Conv2D(128, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_3_2', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(self._2Dpool__(pnumber=3, pfilter=2, ptype=self.pooling))\n",
    "        \n",
    "        #block 4\n",
    "        self.model.add(Conv2D(256, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_4_1', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(Conv2D(256, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_4_2', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(self._2Dpool__(pnumber=4, pfilter=2, ptype=self.pooling))\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #block 5\n",
    "        self.model.add(Conv2D(512, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_5_1', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(Conv2D(512, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_5_2', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(self._2Dpool__(pnumber=5, pfilter=2, ptype=self.pooling))\n",
    "        \n",
    "        #block 6\n",
    "        self.model.add(Conv2D(1024, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_6_1', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(Conv2D(1024, (3,3), strides=(1,1), padding='same', \n",
    "                           activation=self.get_activation_function(func=self.activations),\n",
    "                           name='conv_6_2', kernel_regularizer=self.get_regularizer()))\n",
    "        self.model.add(self._2Dpool__(pnumber=6, pfilter=2, ptype=self.pooling))\n",
    "        '''\n",
    "        self.model.add(self.flaten())\n",
    "        self.model.add(self.flaten())\n",
    "        \n",
    "        self.model=self.fully_dense(activation=self.fcactivations, dropout=0.6, model=self.model)\n",
    "        self.architecture_summary(self.model, input_shape)\n",
    "        self.compile_model(self.model, self.optimizers, self.learning_rates, self.lossfunc)\n",
    "        \n",
    "        return None\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params={\n",
    "        'num_classes':len(mammo_mias_classes), 'class_names':mammo_mias_classes, \n",
    "        'input_dataset':\"../DATASETS/IMAGE-BASED-DATASET/data/mias\", 'testing_dataset':\"../DATASETS/IMAGE-BASED-DATASET/data/mias\",\n",
    "        'img_size':mammo_img_size,  'num_channels':mammo_num_channels,\n",
    "        'train_split':train_split, 'test_split':test_split, 'eval_split':eval_split,\n",
    "        'train_using':train_using_mammo_mias, 'K':K\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use this to fetech images and store them in the array  and split them to train , test and evaluation\n",
    "mammo_input_mias=InputProcessor(data_params=data_params) \n",
    "mammo_input_mias.get_train_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647716ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain=mammo_input_mias.get_training_data()\n",
    "xeval, yeval=mammo_input_mias.get_eval_data()\n",
    "x_test, y_test=mammo_input_mias.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt, lr=optimizers[1], learning_rates[4]\n",
    "mamocnn_paras={\n",
    "    'learning_rates':lr,  'optimizers':opt, 'activations':activations[1], \n",
    "    'pooling':pooling[1], 'regularizers':regularizers[1], 'fcactivations':fcactivations[0], \n",
    "    'lossfunc':lossfunc[0], 'cnn_epoch':cnn_epoch, 'batch_size':batch_size,        \n",
    "    'log_mode':log_mode, 'models_path':models_path, 'model_filename':mammo_model_filename,\n",
    "    'save_results_dir':save_results_dir, 'show':show, 'K':K, \n",
    "    'checkpoint_epoch':40, 'fromCheckpoint':False, 'train_model': True,\n",
    "    \n",
    "    'num_classes':len(mammo_mias_classes), 'class_names':mammo_mias_classes, \n",
    "    'img_size':mammo_img_size, 'num_channels':mammo_num_channels, \n",
    "    'input_source':mammo_input_mias,\n",
    "    \"experiment\":\"mammocnn_eph{}_optz{}_lr{}\".format(cnn_epoch,opt,lr),\n",
    "    \"filename\":\"mammocnn_eph{}_optz{}_lr{}\".format(cnn_epoch,opt,lr),\n",
    "    'optimzed_result_file':\"optimized_mammo_eph{}_{}_lr{}\".format(cnn_epoch,opt,lr),\n",
    "    \n",
    "    'checkpoint_path':mammo_checkpoint_path, \"save_multimodal_results_dir\":save_mammo_results_dir,         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf39adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnn=MammoCNN(mamocnn_paras=mamocnn_paras)\n",
    "mcnn.build_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b09a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mamocnn_paras['train_model']:\n",
    "    if mamocnn_paras['fromCheckpoint']:\n",
    "        training_outcome=mcnn.load_trained_model(xtrain, ytrain, xeval, yeval)\n",
    "    else:\n",
    "        training_outcome=mcnn.trainmodel(mcnn.model, xtrain, ytrain, xeval, yeval)\n",
    "\n",
    "    mcnn.extract_vector_features(mcnn.model, xtrain, ytrain, xeval, yeval, 'pool_4')\n",
    "else:\n",
    "    mcnn.extract_vector_features(mcnn.model, xtrain, ytrain, xeval, yeval, 'pool_4') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f4c8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cdde21c",
   "metadata": {},
   "source": [
    "# Text Based DATA Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212bb792",
   "metadata": {},
   "source": [
    "* BreastEW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "881bd982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: ../DATASETS/TEXT-BASED-DATASET/text_based_data_set/UCI/BreastEW/BreastEW.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"../DATASETS/TEXT-BASED-DATASET/text_based_data_set/UCI/BreastEW/BreastEW.csv\"\n",
    "save_dir = \"./outputs/checkpoints/original_text_data_features/\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"File found: {file_path}\")\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.iloc[:, :-1].values  # Convert to numpy array\n",
    "    y = df.iloc[:, -1]   \n",
    "    \n",
    "    # Convert target values: 2 -> [0,1], 1 -> [1,0]\n",
    "    y_encoded = np.array([[1,0] if label == 1 else [0,1] for label in y])\n",
    "    \n",
    "    # First split: 75% train, 25% temp\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, train_size=0.75, random_state=42)\n",
    "    \n",
    "    # Second split: 15% test, 10% eval (from the remaining 25%)\n",
    "    X_eval, X_test, y_eval, y_test = train_test_split(X_temp, y_temp, test_size=0.6, random_state=42)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the arrays\n",
    "    np.save(os.path.join(save_dir, 'breastEW_train_data.npy'), X_train)\n",
    "    np.save(os.path.join(save_dir, 'breastEW_train_label.npy'), y_train)\n",
    "    np.save(os.path.join(save_dir, 'breastEW_eval_data.npy'), X_eval)\n",
    "    np.save(os.path.join(save_dir, 'breastEW_eval_label.npy'), y_eval)\n",
    "    np.save(os.path.join(save_dir, 'breastEW_test_data.npy'), X_test)\n",
    "    np.save(os.path.join(save_dir, 'breastEW_test_label.npy'), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86008c47",
   "metadata": {},
   "source": [
    "* sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93c6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"../DATASETS/TEXT-BASED-DATASET/text_based_data_set/UCI/Sonar/Sonar.csv\"\n",
    "save_dir = \"./outputs/checkpoints/original_text_data_features/\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    # Convert target values to one-hot encoded format\n",
    "    y_encoded = np.zeros((len(y), 2))\n",
    "    for i, label in enumerate(y):\n",
    "        if label == 1:\n",
    "            y_encoded[i] = [1, 0]\n",
    "        else:\n",
    "            y_encoded[i] = [0, 1]\n",
    "    \n",
    "    # First split: 75% train, 25% temp\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, train_size=0.75, random_state=42)\n",
    "    \n",
    "    # Second split: 15% test, 10% eval (from the remaining 25%)\n",
    "    X_eval, X_test, y_eval, y_test = train_test_split(X_temp, y_temp, test_size=0.6, random_state=42)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the arrays\n",
    "    np.save(os.path.join(save_dir, 'Sonar_train_data.npy'), X_train)\n",
    "    np.save(os.path.join(save_dir, 'Sonar_train_label.npy'), y_train)\n",
    "    np.save(os.path.join(save_dir, 'Sonar_eval_data.npy'), X_eval)\n",
    "    np.save(os.path.join(save_dir, 'Sonar_eval_label.npy'), y_eval)\n",
    "    np.save(os.path.join(save_dir, 'Sonar_test_data.npy'), X_test)\n",
    "    np.save(os.path.join(save_dir, 'Sonar_test_label.npy'), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8413b",
   "metadata": {},
   "source": [
    "* CongressEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3a4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"../DATASETS/TEXT-BASED-DATASET/text_based_data_set/UCI/CongressEW/CongressEW.csv\"\n",
    "save_dir = \"./outputs/checkpoints/original_text_data_features/\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    # Convert target values to one-hot encoded format\n",
    "    y_encoded = np.zeros((len(y), 2))\n",
    "    for i, label in enumerate(y):\n",
    "        if label == 1:\n",
    "            y_encoded[i] = [1, 0]\n",
    "        else:\n",
    "            y_encoded[i] = [0, 1]\n",
    "    \n",
    "    # First split: 75% train, 25% temp\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, train_size=0.75, random_state=42)\n",
    "    \n",
    "    # Second split: 15% test, 10% eval (from the remaining 25%)\n",
    "    X_eval, X_test, y_eval, y_test = train_test_split(X_temp, y_temp, test_size=0.6, random_state=42)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the arrays\n",
    "    np.save(os.path.join(save_dir, 'CongressEW_train_data.npy'), X_train)\n",
    "    np.save(os.path.join(save_dir, 'CongressEW_train_label.npy'), y_train)\n",
    "    np.save(os.path.join(save_dir, 'CongressEW_eval_data.npy'), X_eval)\n",
    "    np.save(os.path.join(save_dir, 'CongressEW_eval_label.npy'), y_eval)\n",
    "    np.save(os.path.join(save_dir, 'CongressEW_test_data.npy'), X_test)\n",
    "    np.save(os.path.join(save_dir, 'CongressEW_test_label.npy'), y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
